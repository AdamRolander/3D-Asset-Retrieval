{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216324aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Comparison logic requires statistical tests\n",
    "from scipy.stats import ttest_rel, wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb4bf04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Found: ../data/index/text_index.faiss\n",
      "[OK] Found: ../data/index/text_index_metadata.csv\n",
      "[OK] Found: ../tests/baseline_robustness_tests.json\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Configuration\n",
    "\n",
    "# Set plot style for better visuals\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "FAISS_INDEX_PATH = \"../data/index/text_index.faiss\"\n",
    "METADATA_PATH = \"../data/index/text_index_metadata.csv\"\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "TESTS_JSON_PATH = \"../tests/baseline_robustness_tests.json\"\n",
    "TOP_K_DEFAULT = 10\n",
    "\n",
    "# Helper to check paths\n",
    "def check_paths():\n",
    "    paths = [FAISS_INDEX_PATH, METADATA_PATH, TESTS_JSON_PATH]\n",
    "    for p in paths:\n",
    "        if not os.path.exists(p):\n",
    "            print(f\"[WARNING] File not found: {p}\")\n",
    "        else:\n",
    "            print(f\"[OK] Found: {p}\")\n",
    "\n",
    "check_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28260020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resources():\n",
    "    \"\"\"\n",
    "    load FAISS index, metadata DataFrame, and MiniLM model.\n",
    "\n",
    "    returns:\n",
    "        index: FAISS index\n",
    "        meta_df: DataFrame with columns ['uid', 'caption', 'image_path']\n",
    "        model: SentenceTransformer model for query encoding\n",
    "    \"\"\"\n",
    "    if not os.path.exists(FAISS_INDEX_PATH):\n",
    "        raise FileNotFoundError(f\"FAISS index not found at {FAISS_INDEX_PATH}\")\n",
    "    if not os.path.exists(METADATA_PATH):\n",
    "        raise FileNotFoundError(f\"Metadata CSV not found at {METADATA_PATH}\")\n",
    "\n",
    "    print(\"[INFO] Loading FAISS index from disk...\")\n",
    "    index = faiss.read_index(FAISS_INDEX_PATH)\n",
    "\n",
    "    print(\"[INFO] Loading metadata from disk...\")\n",
    "    meta_df = pd.read_csv(METADATA_PATH)\n",
    "    print(f\"[INFO] Loaded metadata with {len(meta_df)} rows.\")\n",
    "\n",
    "    print(f\"[INFO] Loading MiniLM model ({MODEL_NAME}) for query encoding...\")\n",
    "    model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "    return index, meta_df, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11577769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_normalize_query(model, query: str) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    encode a single query string with MiniLM and L2-normalize the embedding\n",
    "\n",
    "    input:\n",
    "        model: SentenceTransformer\n",
    "        query: text string\n",
    "\n",
    "    output:\n",
    "        q_emb_norm: NumPy array of shape (1, D), dtype float32\n",
    "    \"\"\"\n",
    "    q_emb = model.encode([query], show_progress_bar=False)\n",
    "    norms = np.linalg.norm(q_emb, axis=1, keepdims=True) + 1e-12\n",
    "    q_emb_norm = (q_emb / norms).astype(\"float32\")\n",
    "    return q_emb_norm\n",
    "\n",
    "\n",
    "def cosine_similarity(model, q1: str, q2: str) -> float:\n",
    "    \"\"\"\n",
    "    compute cosine similarity between two query strings\n",
    "    using the same MiniLM encoder and L2-normalization.\n",
    "    \"\"\"\n",
    "    emb1 = encode_and_normalize_query(model, q1)  # shape (1, D)\n",
    "    emb2 = encode_and_normalize_query(model, q2)  # shape (1, D)\n",
    "\n",
    "    # since they are normalized, cosine = dot product\n",
    "    sim = float(np.dot(emb1[0], emb2[0]))\n",
    "    return sim\n",
    "\n",
    "\n",
    "def compute_cosine_similarity_drop(\n",
    "    model,\n",
    "    original_queries: list,\n",
    "    perturbed_queries: list\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity drop between original and perturbed queries.\n",
    "    \n",
    "    Args:\n",
    "        model: SentenceTransformer model\n",
    "        original_queries: List of original query strings\n",
    "        perturbed_queries: List of perturbed query strings (same length)\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            'similarities': list of floats,\n",
    "            'mean_similarity': float,\n",
    "            'mean_drop': float (1 - mean_similarity),\n",
    "            'std_similarity': float,\n",
    "            'min_similarity': float,\n",
    "            'max_similarity': float\n",
    "        }\n",
    "    \"\"\"\n",
    "    if len(original_queries) != len(perturbed_queries):\n",
    "        raise ValueError(\"Query lists must have same length\")\n",
    "    \n",
    "    similarities = []\n",
    "    for orig, pert in zip(original_queries, perturbed_queries):\n",
    "        sim = cosine_similarity(model, orig, pert)\n",
    "        similarities.append(sim)\n",
    "    \n",
    "    similarities = np.array(similarities)\n",
    "    \n",
    "    return {\n",
    "        'similarities': similarities.tolist(),\n",
    "        'mean_similarity': float(np.mean(similarities)),\n",
    "        'mean_drop': float(1.0 - np.mean(similarities)),\n",
    "        'std_similarity': float(np.std(similarities)),\n",
    "        'min_similarity': float(np.min(similarities)),\n",
    "        'max_similarity': float(np.max(similarities))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35633964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(index, meta_df, model, query: str, top_k: int = TOP_K_DEFAULT):\n",
    "    \"\"\"\n",
    "    run a text query against the FAISS index and return top k results\n",
    "\n",
    "    inputs:\n",
    "        index: FAISS index (IndexFlatIP with normalized embeddings)\n",
    "        meta_df: DataFrame with metadata (uid, caption, image_path)\n",
    "        model: MiniLM SentenceTransformer\n",
    "        query: text query string\n",
    "        top_k: number of results to return\n",
    "\n",
    "    output:\n",
    "        results: list of dicts like:\n",
    "            {\n",
    "                \"rank\": int,\n",
    "                \"idx\": int,\n",
    "                \"uid\": str,\n",
    "                \"caption\": str,\n",
    "                \"score\": float,\n",
    "            }\n",
    "    \"\"\"\n",
    "    q_emb_norm = encode_and_normalize_query(model, query)\n",
    "    scores, indices = index.search(q_emb_norm, top_k)\n",
    "    scores = scores[0]\n",
    "    indices = indices[0]\n",
    "\n",
    "    results = []\n",
    "    for rank, (idx, score) in enumerate(zip(indices, scores), start=1):\n",
    "        row = meta_df.iloc[idx]\n",
    "        results.append(\n",
    "            {\n",
    "                \"rank\": rank,\n",
    "                \"idx\": int(idx),\n",
    "                \"uid\": row[\"uid\"],\n",
    "                \"caption\": row[\"caption\"],\n",
    "                \"score\": float(score),\n",
    "            }\n",
    "        )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c224515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_random_subset(\n",
    "    index,\n",
    "    meta_df,\n",
    "    model,\n",
    "    num_samples: int = 100,\n",
    "    top_k: int = 10,\n",
    "    seed: int = 42,\n",
    "):\n",
    "    \"\"\"\n",
    "    evaluate retrieval performance on a random subset of captions.\n",
    "\n",
    "    for each sampled row:\n",
    "        - use its caption as the query\n",
    "        - treat its UID as the \"correct\" asset\n",
    "        - run search(top_k)\n",
    "        - compute R@1, R@5, R@10 and Reciprocal Rank\n",
    "\n",
    "    returns:\n",
    "        dict with averaged metrics: R@1, R@5, R@10, MRR, num_samples\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(meta_df)\n",
    "    if num_samples > n:\n",
    "        num_samples = n\n",
    "\n",
    "    sampled_indices = rng.choice(n, size=num_samples, replace=False)\n",
    "\n",
    "    r_at_1 = 0\n",
    "    r_at_5 = 0\n",
    "    r_at_10 = 0\n",
    "    mrr_sum = 0.0\n",
    "    individual_scores = []\n",
    "\n",
    "    for count, idx in enumerate(sampled_indices, start=1):\n",
    "        row = meta_df.iloc[idx]\n",
    "        true_uid = row[\"uid\"]\n",
    "        query_caption = row[\"caption\"]\n",
    "\n",
    "        results = search(index, meta_df, model, query_caption, top_k=top_k)\n",
    "\n",
    "        # find rank of the correct UID in the results\n",
    "        rank_of_true = None\n",
    "        for r in results:\n",
    "            if r[\"uid\"] == true_uid:\n",
    "                rank_of_true = r[\"rank\"]\n",
    "                break\n",
    "\n",
    "        individual_scores.append({\n",
    "            'query': query_caption,\n",
    "            'true_uid': true_uid,\n",
    "            'rank': rank_of_true,\n",
    "            'found_in_top1': rank_of_true == 1 if rank_of_true else False,\n",
    "            'found_in_top5': rank_of_true <= 5 if rank_of_true else False,\n",
    "            'found_in_top10': rank_of_true <= 10 if rank_of_true else False,\n",
    "            'reciprocal_rank': 1.0 / rank_of_true if rank_of_true else 0.0\n",
    "        })\n",
    "\n",
    "        if rank_of_true is not None:\n",
    "            if rank_of_true <= 1:\n",
    "                r_at_1 += 1\n",
    "            if rank_of_true <= 5:\n",
    "                r_at_5 += 1\n",
    "            if rank_of_true <= 10:\n",
    "                r_at_10 += 1\n",
    "\n",
    "            # Reciprocal Rank\n",
    "            mrr_sum += 1.0 / rank_of_true\n",
    "\n",
    "        if count % 10 == 0:\n",
    "            print(f\"[INFO] Processed {count}/{num_samples} samples...\")\n",
    "\n",
    "    num = float(num_samples)\n",
    "    metrics = {\n",
    "        \"R@1\": r_at_1 / num,\n",
    "        \"R@5\": r_at_5 / num,\n",
    "        \"R@10\": r_at_10 / num,\n",
    "        \"MRR\": mrr_sum / num,\n",
    "        \"num_samples\": num_samples,\n",
    "        \"individual_scores\": individual_scores,\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd71ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_robustness_ratio(\n",
    "    index,\n",
    "    meta_df,\n",
    "    model,\n",
    "    original_queries: list,\n",
    "    perturbed_queries: list,\n",
    "    ground_truth_uids: list,\n",
    "    k_values: list = [1, 5, 10]\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Compute Robustness Ratio: RR = R@k(perturbed) / R@k(original).\n",
    "    \n",
    "    Args:\n",
    "        index: FAISS index\n",
    "        meta_df: Metadata DataFrame\n",
    "        model: SentenceTransformer model\n",
    "        original_queries: List of original query strings\n",
    "        perturbed_queries: List of perturbed versions (same length)\n",
    "        ground_truth_uids: List of correct UIDs for each query\n",
    "        k_values: List of k values to test (default: [1, 5, 10])\n",
    "    \n",
    "    Returns:\n",
    "        {\n",
    "            'original': {'R@1': float, 'R@5': float, 'R@10': float},\n",
    "            'perturbed': {'R@1': float, 'R@5': float, 'R@10': float},\n",
    "            'robustness_ratios': {'RR@1': float, 'RR@5': float, 'RR@10': float},\n",
    "            'num_queries': int\n",
    "        }\n",
    "    \"\"\"\n",
    "    if len(original_queries) != len(perturbed_queries) != len(ground_truth_uids):\n",
    "        raise ValueError(\"All input lists must have same length\")\n",
    "    \n",
    "    def compute_recall_at_k(queries, uids, k):\n",
    "        \"\"\"Helper: compute R@k for a set of queries.\"\"\"\n",
    "        hits = 0\n",
    "        for query, true_uid in zip(queries, uids):\n",
    "            results = search(index, meta_df, model, query, top_k=k)\n",
    "            if any(r['uid'] == true_uid for r in results):\n",
    "                hits += 1\n",
    "        return hits / len(queries) if queries else 0.0\n",
    "    \n",
    "    # Compute R@k for original and perturbed queries\n",
    "    results = {\n",
    "        'original': {},\n",
    "        'perturbed': {},\n",
    "        'robustness_ratios': {},\n",
    "        'num_queries': len(original_queries)\n",
    "    }\n",
    "    \n",
    "    for k in k_values:\n",
    "        r_orig = compute_recall_at_k(original_queries, ground_truth_uids, k)\n",
    "        r_pert = compute_recall_at_k(perturbed_queries, ground_truth_uids, k)\n",
    "        \n",
    "        results['original'][f'R@{k}'] = r_orig\n",
    "        results['perturbed'][f'R@{k}'] = r_pert\n",
    "        results['robustness_ratios'][f'RR@{k}'] = r_pert / r_orig if r_orig > 0 else 0.0\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def run_robustness_tests(index, meta_df, model, tests_path, top_ks=(1, 5, 10)):\n",
    "    \"\"\"\n",
    "    Run robustness tests over a set of query families.\n",
    "\n",
    "    tests: list of dicts, each like:\n",
    "        {\n",
    "            \"name\": str,\n",
    "            \"orig\": str,\n",
    "            \"orig_type\": str (optional, default \"canonical\"),\n",
    "            \"variants\": [\n",
    "                {\"query\": str, \"type\": str},\n",
    "                ...\n",
    "            ]\n",
    "        }\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(tests_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tests = json.load(f)\n",
    "\n",
    "\n",
    "    max_k = max(top_ks)\n",
    "    top_ks_sorted = sorted(top_ks)\n",
    "\n",
    "    def classify_rank(rank):\n",
    "        if rank is None:\n",
    "            return \"miss\"\n",
    "        for k in top_ks_sorted:\n",
    "            if rank <= k:\n",
    "                return f\"R@{k}\"\n",
    "        return \"miss\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    def evaluate_query(query, query_type, variant_label, variant_type, target_uid, test_name):\n",
    "        res = search(index, meta_df, model, query, top_k=max_k)\n",
    "\n",
    "        rank = None\n",
    "        for r in res:\n",
    "            if r[\"uid\"] == target_uid:\n",
    "                rank = r[\"rank\"]\n",
    "                break\n",
    "\n",
    "        success = classify_rank(rank)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"test_name\": test_name,\n",
    "                \"query_type\": query_type,        # \"orig\" or \"variant\"\n",
    "                \"variant_label\": variant_label,  # \"orig\" or the variant query\n",
    "                \"variant_type\": variant_type,    # e.g. \"typo\", \"hypernym\", etc.\n",
    "                \"query\": query,\n",
    "                \"rank\": rank,\n",
    "                \"success_level\": success,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        return rank, success\n",
    "\n",
    "    print(\"[INFO] Running robustness tests (R@1 / R@5 / R@10)...\")\n",
    "\n",
    "    # Collect data for aggregate metrics\n",
    "    all_original_queries = []\n",
    "    all_variant_queries = []\n",
    "    all_target_uids = []\n",
    "\n",
    "    for test in tests:\n",
    "        name = test.get(\"name\", \"UNKNOWN_TEST\")\n",
    "        orig_query = test[\"orig\"]\n",
    "        orig_type = test.get(\"orig_type\", \"canonical\")\n",
    "        variants = test.get(\"variants\", [])\n",
    "\n",
    "        print(\"\\n\" + \"-\" * 80+\"\\n\")\n",
    "        print(f\"[TEST] {name}\")\n",
    "        print(f\"  Original query: {orig_query}\")\n",
    "\n",
    "        # determine target UID from original query (top-1 result)\n",
    "        orig_results = search(index, meta_df, model, orig_query, top_k=max_k)\n",
    "        orig_top = orig_results[0]\n",
    "        target_uid = orig_top[\"uid\"]\n",
    "        print(\n",
    "            \"  [ORIG TOP-1] uid={}  score={:.4f}\".format(\n",
    "                target_uid, orig_top[\"score\"]\n",
    "            )\n",
    "        )\n",
    "        print(\"              caption: {}\".format(orig_top[\"caption\"]))\n",
    "\n",
    "        # evaluate original query\n",
    "        orig_rank, orig_level = evaluate_query(\n",
    "            query=orig_query,\n",
    "            query_type=\"orig\",\n",
    "            variant_label=\"orig\",\n",
    "            variant_type=orig_type,\n",
    "            target_uid=target_uid,\n",
    "            test_name=name,\n",
    "        )\n",
    "        print(f\"\\n  => Original: success={orig_level}  rank={orig_rank}  type={orig_type}\")\n",
    "\n",
    "        # pretty print variants in a table-like format\n",
    "        if variants:\n",
    "            print(\"\\n  Variants:\")\n",
    "            # header\n",
    "            print(\"    {succ:<7}  {rank:<4}  {vtype:<20}  {query}\".format(\n",
    "                succ=\"success\",\n",
    "                rank=\"rank\",\n",
    "                vtype=\"type\",\n",
    "                query=\"query\",\n",
    "            ))\n",
    "            print(\"    {:-<7}  {:-<4}  {:-<20}  {:-<40}\".format(\"\", \"\", \"\", \"\"))\n",
    "\n",
    "            for v in variants:\n",
    "                q = v[\"query\"]\n",
    "                v_type = v.get(\"type\", \"unknown\")\n",
    "\n",
    "                rank_v, level_v = evaluate_query(\n",
    "                    query=q,\n",
    "                    query_type=\"variant\",\n",
    "                    variant_label=q,\n",
    "                    variant_type=v_type,\n",
    "                    target_uid=target_uid,\n",
    "                    test_name=name,\n",
    "                )\n",
    "\n",
    "                rank_str = \"-\" if rank_v is None else str(rank_v)\n",
    "                print(\n",
    "                    \"    {succ:<7}  {rank:<4}  {vtype:<20}  {query}\".format(\n",
    "                        succ=level_v,\n",
    "                        rank=rank_str,\n",
    "                        vtype=v_type[:20],\n",
    "                        query=q,\n",
    "                    )\n",
    "                )\n",
    "                \n",
    "                # Collect for aggregate metrics\n",
    "                all_original_queries.append(orig_query)\n",
    "                all_variant_queries.append(q)\n",
    "                all_target_uids.append(target_uid)\n",
    "\n",
    "    # Compute aggregate metrics after all tests\n",
    "    if all_variant_queries:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"AGGREGATE METRICS (across all tests):\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        # Compute δSim\n",
    "        delta_sim = compute_cosine_similarity_drop(\n",
    "            model,\n",
    "            all_original_queries,\n",
    "            all_variant_queries\n",
    "        )\n",
    "        \n",
    "        # Compute Robustness Ratio\n",
    "        rr_metrics = compute_robustness_ratio(\n",
    "            index, meta_df, model,\n",
    "            all_original_queries,\n",
    "            all_variant_queries,\n",
    "            all_target_uids,\n",
    "            k_values=[1, 5, 10]\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nCosine Similarity Drop (δSim):\")\n",
    "        print(f\"  Mean similarity: {delta_sim['mean_similarity']:.4f}\")\n",
    "        print(f\"  Mean drop (δSim): {delta_sim['mean_drop']:.4f}\")\n",
    "        print(f\"  Std deviation:   {delta_sim['std_similarity']:.4f}\")\n",
    "        print(f\"  Range:           [{delta_sim['min_similarity']:.4f}, {delta_sim['max_similarity']:.4f}]\")\n",
    "        \n",
    "        print(f\"\\nRobustness Ratio (RR):\")\n",
    "        print(f\"  Original R@1:  {rr_metrics['original']['R@1']:.3f}\")\n",
    "        print(f\"  Perturbed R@1: {rr_metrics['perturbed']['R@1']:.3f}\")\n",
    "        print(f\"  RR@1:          {rr_metrics['robustness_ratios']['RR@1']:.3f}\")\n",
    "        print(f\"  RR@5:          {rr_metrics['robustness_ratios']['RR@5']:.3f}\")\n",
    "        print(f\"  RR@10:         {rr_metrics['robustness_ratios']['RR@10']:.3f}\")\n",
    "        print(f\"  Total queries: {rr_metrics['num_queries']}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "609d486f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: 678f2a20-854f-44e6-9a77-ff1184b777a8)')' thrown while requesting HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/./modules.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading FAISS index from disk...\n",
      "[INFO] Loading metadata from disk...\n",
      "[INFO] Loaded metadata with 10000 rows.\n",
      "[INFO] Loading MiniLM model (all-MiniLM-L6-v2) for query encoding...\n"
     ]
    }
   ],
   "source": [
    "# load index, metadata, and text encoder\n",
    "index, meta_df, model = load_resources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48fbdf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[QUERY] white sofa with wooden legs\n",
      "  1. uid=53d0b31aa7f84bc4b1733224963d0114  score=0.9310\n",
      "     caption: A white sofa with wooden legs and a wooden frame.\n",
      "  2. uid=f761658fafcc42a78fd42912ef9f57e9  score=0.8172\n",
      "     caption: A modern wooden sofa with white cushions and pillows, featuring a slatted backrest and solid legs.\n",
      "  3. uid=69ed1dad032444cdb5bbb6fb883982e3  score=0.7854\n",
      "     caption: A white sofa with curved features and an integrated wall light and shelf.\n",
      "  4. uid=90be7242f24749c3a8e0b0a69c616fc1  score=0.7761\n",
      "     caption: Brown leather Chesterfield sofa with metal legs.\n",
      "  5. uid=d0b4812ad71b4d7f9eda54f48b65362a  score=0.7688\n",
      "     caption: A white couch, bench, or sofa on a gray background.\n",
      "\n",
      "================================================================================\n",
      "[QUERY] airplane\n",
      "  1. uid=ed60862e215a498a9a214ca51af1bf32  score=0.7869\n",
      "     caption: A white airplane.\n",
      "  2. uid=042f8ae68d594a0497d10b5f73e154d9  score=0.7335\n",
      "     caption: A small blue airplane.\n",
      "  3. uid=10891bcc6a924d33b0c38dda490f55ac  score=0.7335\n",
      "     caption: A small blue airplane.\n",
      "  4. uid=a0994a5b9aef423a838b33bb73e48b5a  score=0.7305\n",
      "     caption: A small plane.\n",
      "  5. uid=4e89892c1e2449b591e9d5482d995ab2  score=0.7186\n",
      "     caption: A small white airplane.\n"
     ]
    }
   ],
   "source": [
    "# quick sanity-check queries\n",
    "test_queries = [\n",
    "    \"white sofa with wooden legs\",\n",
    "    \"airplane\",\n",
    "]\n",
    "\n",
    "for q in test_queries:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"[QUERY] {q}\")\n",
    "    results = search(index, meta_df, model, q, top_k=5)\n",
    "    for r in results:\n",
    "        print(f\"  {r['rank']}. uid={r['uid']}  score={r['score']:.4f}\")\n",
    "        print(f\"     caption: {r['caption']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34060ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "[INFO] Starting evaluation on random subset of captions...\n",
      "[INFO] Processed 10/100 samples...\n",
      "[INFO] Processed 20/100 samples...\n",
      "[INFO] Processed 30/100 samples...\n",
      "[INFO] Processed 40/100 samples...\n",
      "[INFO] Processed 50/100 samples...\n",
      "[INFO] Processed 60/100 samples...\n",
      "[INFO] Processed 70/100 samples...\n",
      "[INFO] Processed 80/100 samples...\n",
      "[INFO] Processed 90/100 samples...\n",
      "[INFO] Processed 100/100 samples...\n",
      "\n",
      "Evaluation Summary (100 samples):\n",
      "  R@1  = 0.990\n",
      "  R@5  = 1.000\n",
      "  R@10 = 1.000\n",
      "  MRR  = 0.995\n"
     ]
    }
   ],
   "source": [
    "# evaluation on a random subset\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"[INFO] Starting evaluation on random subset of captions...\")\n",
    "\n",
    "metrics = evaluate_random_subset(\n",
    "    index,\n",
    "    meta_df,\n",
    "    model,\n",
    "    num_samples=100,\n",
    "    top_k=10,\n",
    ")\n",
    "\n",
    "print(\"\\nEvaluation Summary ({} samples):\".format(metrics[\"num_samples\"]))\n",
    "print(\"  R@1  = {:.3f}\".format(metrics[\"R@1\"]))\n",
    "print(\"  R@5  = {:.3f}\".format(metrics[\"R@5\"]))\n",
    "print(\"  R@10 = {:.3f}\".format(metrics[\"R@10\"]))\n",
    "print(\"  MRR  = {:.3f}\".format(metrics[\"MRR\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea065abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running robustness tests (R@1 / R@5 / R@10)...\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[TEST] penguin\n",
      "  Original query: A stylized purple penguin with a yellow beak, black wings and feet with yellow tips, and a gradient orange-yellow belly.\n",
      "  [ORIG TOP-1] uid=1e00453a031940b48a4ea1ea16bb1a88  score=1.0000\n",
      "              caption: A stylized purple penguin with a yellow beak, black wings and feet with yellow tips, and a gradient orange-yellow belly.\n",
      "\n",
      "  => Original: success=R@1  rank=1  type=canonical\n",
      "\n",
      "  Variants:\n",
      "    success  rank  type                  query\n",
      "    -------  ----  --------------------  ----------------------------------------\n",
      "    miss     -     typo                  purple pgnguin\n",
      "    R@1      1     paraphrase            stylized penguin with yellow beak\n",
      "    R@5      3     filler                a cute small cartoon penguin with with wings and black eyes\n",
      "    miss     -     synonym               A purple bird with wings\n",
      "    miss     -     synonym               A bird with a yellow beak\n",
      "    miss     -     synonym               A bird with a yellow beak and wings\n",
      "    R@1      1     filler                A 3D model of a purple pengin\n",
      "    R@1      1     filler                A 3D generated model of a purple pengin\n",
      "    R@1      1     reorder               black winged yellow beaked penguin\n",
      "    R@1      1     color                 black and yellow penguin\n",
      "    R@1      1     color                 An image of a black and yellow penguin\n",
      "    R@1      1     filler                a purple penguin small toy\n",
      "    R@1      1     descriptor            an orange penguin\n",
      "    R@1      1     descriptor            a small green penguin\n",
      "    R@10     7     subject               a purple duck with a yellow beak\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[TEST] sports car\n",
      "  Original query: A grey Audi R8 sports car.\n",
      "  [ORIG TOP-1] uid=ab4565513b2b47148a5051a4dce70314  score=1.0000\n",
      "              caption: A grey Audi R8 sports car.\n",
      "\n",
      "  => Original: success=R@1  rank=1  type=canonical\n",
      "\n",
      "  Variants:\n",
      "    success  rank  type                  query\n",
      "    -------  ----  --------------------  ----------------------------------------\n",
      "    R@1      1     smaller               Audi R8\n",
      "    R@1      1     small                 grey Audi R8\n",
      "    R@1      1     paraphrase            Audi R8 sports car\n",
      "    miss     -     paraphrase only       sports car\n",
      "    R@5      5     paraphrase color      grey sports car\n",
      "    R@5      2     color only            grey car\n",
      "    miss     -     synonym               sports vehicle\n",
      "    miss     -     synonym               racing car\n",
      "    miss     -     typo                  grey var\n",
      "    R@1      1     filler                an Audi driving down the road\n",
      "    R@1      1     wrong color           a blue Audi R8 sports car\n",
      "    miss     -     wrong                 a red Ferrari sports car\n",
      "    R@5      2     similar               a parked grey coupe\n",
      "    R@5      2     subject change        a grey Ferrari sports car\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "[TEST] table\n",
      "  Original query: A wooden coffee table with a rectangular top, an open shelf, and four square legs. The natural wood finish gives it a warm and inviting look.\n",
      "  [ORIG TOP-1] uid=61f97c8fbbfe4fb982ee622ff5d3d31b  score=1.0000\n",
      "              caption: A wooden coffee table with a rectangular top, an open shelf, and four square legs. The natural wood finish gives it a warm and inviting look.\n",
      "\n",
      "  => Original: success=R@1  rank=1  type=canonical\n",
      "\n",
      "  Variants:\n",
      "    success  rank  type                  query\n",
      "    -------  ----  --------------------  ----------------------------------------\n",
      "    R@5      2     small                 a wooden coffee table\n",
      "    R@5      2     reorder               rectangular coffee table made of wood\n",
      "    R@10     6     reorder               four leg wooden coffee table\n",
      "    R@1      1     one descriptor        natural wood coffee table\n",
      "    R@10     8     leg desv              four square leg coffee table\n",
      "    miss     -     paraphrase_open_shel  open shelf wooden table\n",
      "    miss     -     random                inviting rectangular wooden tabletop\n",
      "    R@1      1     material              natural walnut finish coffee table\n",
      "    R@5      2     material+             natural walnut finish coffee table four legs\n",
      "    R@1      1     material++            a light wood finish coffee table with storage\n",
      "    R@1      1     filler                a wooden coffee table in a living room\n",
      "    R@5      2     specific + filler     a wooden coffee table with four legs in a living room\n",
      "    R@1      1     shape                 a wooden coffee table with round top\n",
      "    R@1      1     shape                 a wooden coffee table with square top\n",
      "    miss     -     wrong                 a wooden bench with four legs\n",
      "    miss     -     wrong specific        a wooden bench with four legs with natural finish\n",
      "    miss     -     wrong                 a wooden cabinet with an open shelf\n",
      "\n",
      "================================================================================\n",
      "AGGREGATE METRICS (across all tests):\n",
      "================================================================================\n",
      "\n",
      "Cosine Similarity Drop (δSim):\n",
      "  Mean similarity: 0.6916\n",
      "  Mean drop (δSim): 0.3084\n",
      "  Std deviation:   0.1248\n",
      "  Range:           [0.3787, 0.8904]\n",
      "\n",
      "Robustness Ratio (RR):\n",
      "  Original R@1:  1.000\n",
      "  Perturbed R@1: 0.435\n",
      "  RR@1:          0.435\n",
      "  RR@5:          0.630\n",
      "  RR@10:         0.696\n",
      "  Total queries: 46\n"
     ]
    }
   ],
   "source": [
    "# small robustness check\n",
    "robustness_results = run_robustness_tests(index, meta_df, model, TESTS_JSON_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645799c1",
   "metadata": {},
   "source": [
    "NOW SECOND PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "57ad8fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model class defined.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import faiss\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel, CLIPVisionModel, CLIPImageProcessor\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# --- Configuration ---\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "TEST_DATA_PATH = \"../data/processed/test_split.csv\" \n",
    "MODEL_BASE_PATH = \"../models/contrastive_base/model_state_dict.pth\"\n",
    "MODEL_AUG_PATH = \"../models/contrastive_finetuned/model_state_dict.pth\" # Augmented model\n",
    "IMAGES_ROOT = \"../\" # Adjust based on where your notebook sits relative to data\n",
    "\n",
    "# Constants matching training\n",
    "MAX_TEXT_LEN = 128\n",
    "PROJECTION_DIM = 384\n",
    "VISION_MODEL = \"openai/clip-vit-base-patch16\"\n",
    "TEXT_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "# --- Model Class (Must match training exactly) ---\n",
    "class MultiModalContrastiveModel(nn.Module):\n",
    "    def __init__(self, text_model_name, vision_model_name, projection_dim=384):\n",
    "        super().__init__()\n",
    "        self.text_encoder = AutoModel.from_pretrained(text_model_name)\n",
    "        self.vision_encoder = CLIPVisionModel.from_pretrained(vision_model_name)\n",
    "        vision_hidden_size = self.vision_encoder.config.hidden_size\n",
    "        self.vision_projection = nn.Linear(vision_hidden_size, projection_dim)\n",
    "        self.logit_scale = nn.Parameter(torch.ones([]) * 2.6592)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, pixel_values):\n",
    "        # Text\n",
    "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = text_outputs.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        text_embeds = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        \n",
    "        # Image\n",
    "        vision_outputs = self.vision_encoder(pixel_values=pixel_values)\n",
    "        image_embeds_raw = vision_outputs.pooler_output \n",
    "        image_embeds = self.vision_projection(image_embeds_raw)\n",
    "        \n",
    "        # Norm\n",
    "        return F.normalize(text_embeds, p=2, dim=1), F.normalize(image_embeds, p=2, dim=1), self.logit_scale.exp()\n",
    "\n",
    "    def encode_text(self, input_ids, attention_mask):\n",
    "        text_outputs = self.text_encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        token_embeddings = text_outputs.last_hidden_state\n",
    "        input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        text_embeds = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        return F.normalize(text_embeds, p=2, dim=1)\n",
    "\n",
    "    def encode_image(self, pixel_values):\n",
    "        vision_outputs = self.vision_encoder(pixel_values=pixel_values)\n",
    "        image_embeds = self.vision_projection(vision_outputs.pooler_output)\n",
    "        return F.normalize(image_embeds, p=2, dim=1)\n",
    "\n",
    "print(\"[INFO] Model class defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6eadcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalDataset(Dataset):\n",
    "    def __init__(self, df, processor):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # Handle path fixing\n",
    "        img_path = row['image_path']\n",
    "        if not img_path.startswith('../'):\n",
    "            img_path = os.path.join(IMAGES_ROOT, img_path)\n",
    "            \n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except:\n",
    "            # Create black image if file missing to prevent crash during eval\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "            \n",
    "        return self.processor(images=image, return_tensors=\"pt\").pixel_values.squeeze(0)\n",
    "\n",
    "def build_image_index(model, df, batch_size=64):\n",
    "    \"\"\"\n",
    "    Passes all test images through the model's Vision Encoder\n",
    "    to create a FAISS index.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    processor = CLIPImageProcessor.from_pretrained(VISION_MODEL)\n",
    "    dataset = EvalDataset(df, processor)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, num_workers=0)\n",
    "    \n",
    "    all_embeddings = []\n",
    "    \n",
    "    print(f\"[INFO] Generating embeddings for {len(df)} test images...\")\n",
    "    with torch.no_grad():\n",
    "        for batch_pixels in tqdm(loader):\n",
    "            batch_pixels = batch_pixels.to(DEVICE)\n",
    "            img_embs = model.encode_image(batch_pixels)\n",
    "            all_embeddings.append(img_embs.cpu().numpy())\n",
    "            \n",
    "    embeddings = np.concatenate(all_embeddings, axis=0).astype('float32')\n",
    "    \n",
    "    # Build Index\n",
    "    index = faiss.IndexFlatIP(PROJECTION_DIM)\n",
    "    index.add(embeddings)\n",
    "    print(f\"[INFO] Index built with {index.ntotal} vectors.\")\n",
    "    return index\n",
    "\n",
    "def load_trained_model(path):\n",
    "    print(f\"[INFO] Loading weights from {path}...\")\n",
    "    model = MultiModalContrastiveModel(TEXT_MODEL, VISION_MODEL, PROJECTION_DIM)\n",
    "    model.load_state_dict(torch.load(path, map_location=DEVICE))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc424c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_supervised_model(model, index, test_df, robustness_tests_path):\n",
    "    \"\"\"\n",
    "    Evaluates a specific model state.\n",
    "    1. Overall Metrics on Test Set (using captions as queries)\n",
    "    2. Robustness Metrics (using perturbed queries)\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(TEXT_MODEL)\n",
    "    \n",
    "    # --- 1. General Test Set Evaluation ---\n",
    "    # We use the ground truth captions in test_df as queries\n",
    "    captions = test_df['caption'].tolist()\n",
    "    \n",
    "    # Tokenize all captions\n",
    "    print(\"[INFO] Encoding test set captions...\")\n",
    "    all_text_embs = []\n",
    "    batch_size = 64\n",
    "    \n",
    "    for i in range(0, len(captions), batch_size):\n",
    "        batch_text = captions[i : i+batch_size]\n",
    "        inputs = tokenizer(batch_text, padding=True, truncation=True, max_length=MAX_TEXT_LEN, return_tensors=\"pt\").to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            emb = model.encode_text(inputs['input_ids'], inputs['attention_mask'])\n",
    "            all_text_embs.append(emb.cpu().numpy())\n",
    "            \n",
    "    query_embs = np.concatenate(all_text_embs, axis=0)\n",
    "    \n",
    "    # Search\n",
    "    k = 10\n",
    "    D, I = index.search(query_embs, k)\n",
    "    \n",
    "    # Calculate R@k\n",
    "    r1, r5, r10, mrr = 0, 0, 0, 0\n",
    "    n = len(test_df)\n",
    "    \n",
    "    for i in range(n):\n",
    "        # The correct image index is simply 'i' because we indexed the dataframe in order\n",
    "        correct_idx = i \n",
    "        retrieved_indices = I[i]\n",
    "        \n",
    "        if correct_idx in retrieved_indices:\n",
    "            rank = np.where(retrieved_indices == correct_idx)[0][0] + 1\n",
    "            mrr += 1.0 / rank\n",
    "            if rank == 1: r1 += 1\n",
    "            if rank <= 5: r5 += 1\n",
    "            if rank <= 10: r10 += 1\n",
    "            \n",
    "    general_metrics = {\n",
    "        \"R@1\": r1/n, \"R@5\": r5/n, \"R@10\": r10/n, \"MRR\": mrr/n\n",
    "    }\n",
    "    \n",
    "    # --- 2. Robustness Tests (Specific JSON) ---\n",
    "    print(\"[INFO] Running Robustness Tests...\")\n",
    "    with open(robustness_tests_path, 'r') as f:\n",
    "        tests = json.load(f)\n",
    "        \n",
    "    rob_results = []\n",
    "    \n",
    "    for test in tests:\n",
    "        # Get target UID from the 'orig' query using the DF lookup\n",
    "        # Note: In Supervised, we find the row with the matching caption or UID.\n",
    "        # Ideally, robustness tests should map to UIDs present in the Test Set.\n",
    "        # If the test query isn't in the test set, we can't evaluate R@k for it easily without the image.\n",
    "        # assumption: The robustness JSON queries correspond to assets IN the test set.\n",
    "        \n",
    "        # Helper: Encode single query\n",
    "        def run_query(q_str):\n",
    "            inp = tokenizer([q_str], padding=True, truncation=True, max_length=MAX_TEXT_LEN, return_tensors=\"pt\").to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                q_emb = model.encode_text(inp['input_ids'], inp['attention_mask']).cpu().numpy()\n",
    "            _, I_q = index.search(q_emb, 10)\n",
    "            return I_q[0]\n",
    "\n",
    "        # Find target index by matching 'orig' query to test_df caption (Approximation)\n",
    "        # In production, tests.json should have 'uid'.\n",
    "        matches = test_df[test_df['caption'] == test['orig']]\n",
    "        if matches.empty:\n",
    "            continue # Skip tests that aren't in this specific test split\n",
    "            \n",
    "        target_idx = matches.index[0] # Index relative to the DF (and thus FAISS)\n",
    "        # We need the integer location in the current test_df, not the pandas Index if it's not reset\n",
    "        target_iloc = test_df.index.get_loc(target_idx)\n",
    "        \n",
    "        # Evaluate Original\n",
    "        indices = run_query(test['orig'])\n",
    "        rank = np.where(indices == target_iloc)[0][0] + 1 if target_iloc in indices else None\n",
    "        \n",
    "        rob_results.append({\n",
    "            \"test_name\": test['name'], \"query_type\": \"orig\", \"variant_type\": \"canonical\",\n",
    "            \"query\": test['orig'], \"rank\": rank\n",
    "        })\n",
    "        \n",
    "        # Evaluate Variants\n",
    "        for v in test['variants']:\n",
    "            indices = run_query(v['query'])\n",
    "            rank = np.where(indices == target_iloc)[0][0] + 1 if target_iloc in indices else None\n",
    "            \n",
    "            rob_results.append({\n",
    "                \"test_name\": test['name'], \"query_type\": \"variant\", \"variant_type\": v['type'],\n",
    "                \"query\": v['query'], \"rank\": rank\n",
    "            })\n",
    "\n",
    "    return general_metrics, rob_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "980bfbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "EVALUATING: Contrastive BASE (10k)\n",
      "========================================\n",
      "[INFO] Loading weights from ../models/contrastive_base/model_state_dict.pth...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\paabl\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch16. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEVALUATING: Contrastive BASE (10k)\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m40\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m model_base = \u001b[43mload_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_BASE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m index_base = build_image_index(model_base, test_df)\n\u001b[32m     15\u001b[39m metrics_base, rob_base = evaluate_supervised_model(\n\u001b[32m     16\u001b[39m     model_base, index_base, test_df, TESTS_JSON_PATH\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mload_trained_model\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_trained_model\u001b[39m(path):\n\u001b[32m     52\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[INFO] Loading weights from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     model = \u001b[43mMultiModalContrastiveModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTEXT_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVISION_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROJECTION_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     model.load_state_dict(torch.load(path, map_location=DEVICE))\n\u001b[32m     55\u001b[39m     model.to(DEVICE)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 31\u001b[39m, in \u001b[36mMultiModalContrastiveModel.__init__\u001b[39m\u001b[34m(self, text_model_name, vision_model_name, projection_dim)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m()\n\u001b[32m     30\u001b[39m \u001b[38;5;28mself\u001b[39m.text_encoder = AutoModel.from_pretrained(text_model_name)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28mself\u001b[39m.vision_encoder = \u001b[43mCLIPVisionModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvision_model_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m vision_hidden_size = \u001b[38;5;28mself\u001b[39m.vision_encoder.config.hidden_size\n\u001b[32m     33\u001b[39m \u001b[38;5;28mself\u001b[39m.vision_projection = nn.Linear(vision_hidden_size, projection_dim)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:277\u001b[39m, in \u001b[36mrestore_default_dtype.<locals>._wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m old_dtype = torch.get_default_dtype()\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    279\u001b[39m     torch.set_default_dtype(old_dtype)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4900\u001b[39m, in \u001b[36mPreTrainedModel.from_pretrained\u001b[39m\u001b[34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[39m\n\u001b[32m   4890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   4891\u001b[39m     gguf_file\n\u001b[32m   4892\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4893\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28misinstance\u001b[39m(device_map, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map.values()) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdisk\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m device_map)\n\u001b[32m   4894\u001b[39m ):\n\u001b[32m   4895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   4896\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mOne or more modules is configured to be mapped to disk. Disk offload is not supported for models \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4897\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mloaded from GGUF files.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4898\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m4900\u001b[39m checkpoint_files, sharded_metadata = \u001b[43m_get_resolved_checkpoint_files\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4902\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvariant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgguf_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4907\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_safetensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4908\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4911\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4912\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4913\u001b[39m \u001b[43m    \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4914\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_remote_code\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_auto_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtransformers_explicit_filename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4918\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4920\u001b[39m is_sharded = sharded_metadata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4921\u001b[39m is_quantized = hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\transformers\\modeling_utils.py:1066\u001b[39m, in \u001b[36m_get_resolved_checkpoint_files\u001b[39m\u001b[34m(pretrained_model_name_or_path, subfolder, variant, gguf_file, from_tf, from_flax, use_safetensors, cache_dir, force_download, proxies, local_files_only, token, user_agent, revision, commit_hash, is_remote_code, transformers_explicit_filename)\u001b[39m\n\u001b[32m   1063\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1064\u001b[39m         \u001b[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[32m   1065\u001b[39m         filename = _add_variant(WEIGHTS_NAME, variant)\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m         resolved_archive_file = \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcached_file_kwargs\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename == _add_variant(WEIGHTS_NAME, variant):\n\u001b[32m   1070\u001b[39m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[32m   1071\u001b[39m     resolved_archive_file = cached_file(\n\u001b[32m   1072\u001b[39m         pretrained_model_name_or_path,\n\u001b[32m   1073\u001b[39m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[32m   1074\u001b[39m         **cached_file_kwargs,\n\u001b[32m   1075\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:322\u001b[39m, in \u001b[36mcached_file\u001b[39m\u001b[34m(path_or_repo_id, filename, **kwargs)\u001b[39m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcached_file\u001b[39m(\n\u001b[32m    265\u001b[39m     path_or_repo_id: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    266\u001b[39m     filename: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    267\u001b[39m     **kwargs,\n\u001b[32m    268\u001b[39m ) -> Optional[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    269\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    270\u001b[39m \u001b[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001b[39;00m\n\u001b[32m    271\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    320\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    321\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m     file = \u001b[43mcached_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     file = file[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m file\n\u001b[32m    324\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m file\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\transformers\\utils\\hub.py:479\u001b[39m, in \u001b[36mcached_files\u001b[39m\u001b[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    477\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(full_filenames) == \u001b[32m1\u001b[39m:\n\u001b[32m    478\u001b[39m         \u001b[38;5;66;03m# This is slightly better for only 1 file\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m         \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m            \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    494\u001b[39m         snapshot_download(\n\u001b[32m    495\u001b[39m             path_or_repo_id,\n\u001b[32m    496\u001b[39m             allow_patterns=full_filenames,\n\u001b[32m   (...)\u001b[39m\u001b[32m    505\u001b[39m             local_files_only=local_files_only,\n\u001b[32m    506\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1007\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m    987\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[32m    988\u001b[39m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[32m    989\u001b[39m         local_dir=local_dir,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1004\u001b[39m         local_files_only=local_files_only,\n\u001b[32m   1005\u001b[39m     )\n\u001b[32m   1006\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1008\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1168\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m# Local file doesn't exist or etag isn't a match => retrieve file from remote (or cache)\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1168\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1177\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1178\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1179\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1180\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n\u001b[32m   1181\u001b[39m         _create_symlink(blob_path, pointer_path, new_blob=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1735\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1728\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m xet_file_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m constants.HF_HUB_DISABLE_XET:\n\u001b[32m   1729\u001b[39m             logger.warning(\n\u001b[32m   1730\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1731\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1732\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1733\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1735\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1744\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m   1745\u001b[39m _chmod_and_move(incomplete_path, destination_path)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:493\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    491\u001b[39m new_resume_size = resume_size\n\u001b[32m    492\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[32m    495\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\urllib3\\response.py:1253\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m (\n\u001b[32m   1249\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp)\n\u001b[32m   1250\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m\n\u001b[32m   1251\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder.has_unconsumed_tail)\n\u001b[32m   1252\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1253\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1255\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1256\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\urllib3\\response.py:1108\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m   1105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m   1106\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m-> \u001b[39m\u001b[32m1108\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1110\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1113\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m data\n\u001b[32m   1114\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m\n\u001b[32m   1115\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoder.has_unconsumed_tail)\n\u001b[32m   1116\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\urllib3\\response.py:1024\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m   1021\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1025\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m   1026\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m   1027\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1032\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m   1033\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m   1034\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\paabl\\OneDrive\\Documents\\GitHub\\3D-Asset-Retrieval\\.venv\\Lib\\site-packages\\urllib3\\response.py:1007\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m   1004\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1006\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1007\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\socket.py:720\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    719\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m720\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1251\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1247\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1248\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1249\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1250\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1253\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\ssl.py:1103\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1101\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1102\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Load Test Data\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "# Ensure clean index for mapping\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "results_store = {}\n",
    "\n",
    "# --- 1. Evaluate BASE Model ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"EVALUATING: Contrastive BASE (10k)\")\n",
    "print(\"=\"*40)\n",
    "model_base = load_trained_model(MODEL_BASE_PATH)\n",
    "index_base = build_image_index(model_base, test_df)\n",
    "\n",
    "metrics_base, rob_base = evaluate_supervised_model(\n",
    "    model_base, index_base, test_df, TESTS_JSON_PATH\n",
    ")\n",
    "results_store['Base'] = {'metrics': metrics_base, 'robustness': rob_base}\n",
    "\n",
    "# Cleanup to save VRAM\n",
    "del model_base\n",
    "del index_base\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# --- 2. Evaluate AUGMENTED Model ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"EVALUATING: Contrastive AUGMENTED (Paraphrased)\")\n",
    "print(\"=\"*40)\n",
    "model_aug = load_trained_model(MODEL_AUG_PATH)\n",
    "index_aug = build_image_index(model_aug, test_df)\n",
    "\n",
    "metrics_aug, rob_aug = evaluate_supervised_model(\n",
    "    model_aug, index_aug, test_df, TESTS_JSON_PATH\n",
    ")\n",
    "results_store['Augmented'] = {'metrics': metrics_aug, 'robustness': rob_aug}\n",
    "\n",
    "# Print General Comparison\n",
    "print(\"\\n--- Final Metric Comparison ---\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Base': results_store['Base']['metrics'],\n",
    "    'Augmented': results_store['Augmented']['metrics']\n",
    "})\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0df4700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font_scale=1.4)\n",
    "palette = sns.color_palette(\"deep\")\n",
    "\n",
    "def plot_model_comparison(results_store):\n",
    "    \n",
    "    # --- FIGURE 4: Side-by-Side Recall Comparison ---\n",
    "    metrics_data = []\n",
    "    for model_name, data in results_store.items():\n",
    "        m = data['metrics']\n",
    "        metrics_data.append({'Model': model_name, 'Metric': 'R@1', 'Score': m['R@1']})\n",
    "        metrics_data.append({'Model': model_name, 'Metric': 'R@5', 'Score': m['R@5']})\n",
    "        metrics_data.append({'Model': model_name, 'Metric': 'R@10', 'Score': m['R@10']})\n",
    "    \n",
    "    df_metrics = pd.DataFrame(metrics_data)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.barplot(data=df_metrics, x='Metric', y='Score', hue='Model', palette=\"viridis\")\n",
    "    \n",
    "    plt.title(\"Supervised Fine-Tuning: Base vs. Augmented Data\", fontweight='bold', pad=15)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.ylabel(\"Recall Score\")\n",
    "    plt.legend(title=\"Training Strategy\")\n",
    "    \n",
    "    # Label bars\n",
    "    for container in ax.containers:\n",
    "        ax.bar_label(container, fmt='%.2f', padding=3, fontsize=10)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- FIGURE 5: Robustness Drop-off Comparison ---\n",
    "    # We want to see how much performance drops on variants for EACH model\n",
    "    \n",
    "    rob_data = []\n",
    "    for model_name, data in results_store.items():\n",
    "        df_r = pd.DataFrame(data['robustness'])\n",
    "        \n",
    "        # Calculate Hit@10 for variants vs originals\n",
    "        # Filter for variants only\n",
    "        df_var = df_r[df_r['query_type'] == 'variant'].copy()\n",
    "        \n",
    "        # Calculate success (Rank <= 10)\n",
    "        df_var['success'] = df_var['rank'].apply(lambda x: 1 if x is not None and x <= 10 else 0)\n",
    "        \n",
    "        # Aggregate by variant type\n",
    "        agg = df_var.groupby('variant_type')['success'].mean().reset_index()\n",
    "        agg['Model'] = model_name\n",
    "        rob_data.append(agg)\n",
    "        \n",
    "    df_rob_comp = pd.concat(rob_data)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Grouped Bar Plot for Robustness\n",
    "    ax2 = sns.barplot(\n",
    "        data=df_rob_comp, \n",
    "        x='variant_type', \n",
    "        y='success', \n",
    "        hue='Model', \n",
    "        palette=\"magma\"\n",
    "    )\n",
    "    \n",
    "    plt.title(\"Robustness Analysis: Resilience to Query Perturbation\", fontweight='bold', pad=15)\n",
    "    plt.ylabel(\"Recall@10 on Perturbed Queries\")\n",
    "    plt.xlabel(\"Perturbation Type\")\n",
    "    plt.ylim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_model_comparison(results_store)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
